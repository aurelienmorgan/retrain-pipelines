{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b49cae8",
   "metadata": {},
   "source": [
    "<div style='background-color: rgba(0, 255, 255, 0.04); border: 1px solid rgba(0, 255, 255, .2);'>\n",
    "<div style='text-align: justify; margin-left: 5px; margin-right: 5px;'>\n",
    "<div style=\"float: left; border-right: 5px solid transparent;\">\n",
    "<table border=\"0\" width=\"350px;\" style=\"background-color: #f5f5f5; float: left;\">\n",
    "    <tr>\n",
    "        <td colspan=2>\n",
    "            <img alt=\"retrain-pipelines\" src=\"https://github.com/user-attachments/assets/19725866-13f9-48c1-b958-35c2e014351a\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=2>\n",
    "            <img alt=\"Hugging Face Hub\" src=\"https://github.com/user-attachments/assets/86c2c8ec-3691-4b2b-a16e-08e99244589c\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=2>\n",
    "            <img alt=\"Metaflow\" width=\"200px\" src=\"https://github.com/user-attachments/assets/ecc20501-869d-4159-b5a0-eb0a117520e5\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"vertical-align: center;\">Unsloth</td>\n",
    "        <td> \n",
    "            <img alt=\"Unsloth\" width=\"40px\" src=\"https://github.com/user-attachments/assets/3bb9244b-8c89-41fa-8b38-c4862763eea1\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"vertical-align: center;\" height=\"40px\">Qwen 2.5</td>\n",
    "        <td>\n",
    "            <img alt=\"Qwen 2.5\" width=\"40px\" src=\"https://github.com/user-attachments/assets/3067f88e-3064-470f-9c8e-2d80c40b3d5c\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"vertical-align: center;\">LitServe</td>\n",
    "        <td> \n",
    "            <img alt=\"LitServe\" width=\"40px\" src=\"https://github.com/user-attachments/assets/b5abcd66-9cb4-420c-ad2c-29bafb0f3b62\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table></div>\n",
    "<br />\n",
    "Welcome to this introductory notebook for the <code>UnslothFuncCallFlow</code> sample pipeline from the <b>retrain-pipelines</b> library.<br />\n",
    "This sample retraining pipeline covers the function-calling NLP use case with LLMs. More specifically, it takes advantages of the <a href=\"https://github.com/unslothai/unsloth\" target=\"_blank\">Unsloth</a> library for memory-efficient training and the flagship <a href=\"https://github.com/QwenLM/Qwen2.5\" target=\"_blank\">Qwen 2.5 1.5B base</a> model, which is a <em>small yet very strong</em> foundation LLM.<br />\n",
    "<br />\n",
    "<div style='background-color: rgba(0, 255, 255, 0.04); border: 1px solid rgba(0, 255, 255, .2);'><center>\n",
    "    Qwen2.5 Technical Report<br />\n",
    "    (<a href=\"https://arxiv.org/abs/2412.15115\">arXiv</a>)\n",
    "</center></div>\n",
    "<br />\n",
    "    The newly retrained model version is then a <u>specialized LoRa adapter</u> with extra knowledge of several thousands functions, excelling at retruning a <u>strict set of actionable fuction-calls</u> from free text.<br />\n",
    "<br />\n",
    "<div style='background-color: rgba(0, 255, 255, 0.04); border: 1px solid rgba(0, 255, 255, .2);'><center>\n",
    "    LoRA: Low-Rank Adaptation of Large Language Models<br />\n",
    "    (<a href=\"https://arxiv.org/abs/2106.09685\">arXiv</a>)\n",
    "</center></div>\n",
    "<br />\n",
    "Like other sample retraining pipelines provided with the <b>retrain-pipelines</b> library, the <code>UnslothFuncCallFlow</code> sample pipeline adapts to your data.<br />\n",
    "<br clear=\"left\" />\n",
    "The specifics of the herein sample pipeline are&nbsp;:\n",
    "    <ul>\n",
    "        <li>\n",
    "            The creation of an augmented and enriched dataset version.\n",
    "        </li>\n",
    "        <li>\n",
    "            Through <u>continued pre-training (CPT)</u>, the addition of some more intrinsic knowledge to a base model, assimilable to a <u>knowledge bank</u> of several thousands functions it will have to refer to once deployed.\n",
    "        </li>\n",
    "        <li>\n",
    "            Through <u>supervised fine-tuning (SFT)</u>, the specialization of the model for the task of returning exhaustive lists of actionable function-calls that any free-text user query may trigger (but not a single one more).\n",
    "        </li>\n",
    "    </ul>\n",
    "<hr />\n",
    "The infrastructure validation (the ability of newly-retrained model versions to accept and respond to inference requests) relies here on <a href=\"https://lightning.ai/docs/litserve/home/\" target=\"_blank\">LitServe</a> where we pack the fitted inference pipeline and put it to the test.\n",
    "<br />\n",
    "We even go further with this, with the implementation of <code>a single-model, multi-adapter inference server</code>, where the caller specifies the name of the adapter that shall be used when infering on (potentially batched) user queries.\n",
    "<br />\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd157f0d",
   "metadata": {},
   "source": [
    "<div style='background-color: rgba(0, 255, 255, 0.04); border: 1px solid rgba(0, 255, 255, .2);'>\n",
    "<div style='text-align: justify; margin-left: 5px; margin-right: 5px;'>\n",
    "Lets go&nbsp;!<br />\n",
    "The herein notebook indeed is here in support of the <code>UnslothFuncCallFlow</code> sample pipeline from the <b>retrain-pipelines</b> library. It is your step-by-step assistant to guide you into mastering it all super fast.<br />\n",
    "<br />\n",
    "From here, you can&nbsp;:\n",
    "<ul>\n",
    "    <li>\n",
    "        Execute a <b>retrain-pipelines</b> run&nbsp;:\n",
    "        <ul>\n",
    "            <li>\n",
    "                inform&nbsp;:\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        the base function-calls dataset\n",
    "                    </li>\n",
    "                    <li>\n",
    "                        the generic dataset to use for data-enrichment\n",
    "                    </li>\n",
    "                    <li>\n",
    "                        the base-model to use as the backbone (default being <em>Qwen 2.5 1.5B</em>)\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>\n",
    "                set independent custom <code> TrainingArguments </code> for the CPT or SFT tasks.\n",
    "            </li>\n",
    "            <li>\n",
    "                set target repositories for the generated <u>dataset-version</u> and <u>model-version</u> when the pipeline executes.\n",
    "            </li>\n",
    "            <li>\n",
    "                launch a <b>retrain-pipeline</b> run\n",
    "            </li>\n",
    "            <li>\n",
    "                even start customizing default <code>dataset README</code>, <code>model README</code> and <code>pipeline_card</code> if you feel like it&nbsp;!\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        do some after-the-fact investigation thanks to the collection of <code>inspectors</code> offered by the <b>retrain-pipelines</b> library\n",
    "    </li>\n",
    "</ul>\n",
    "<br />\n",
    "<p style=\"text-align: justify; color: darkgray;\">\n",
    "<u>REMARK</u>&nbsp;: if you've not done so already, go check <a href=\"https://github.com/aurelienmorgan/retrain-pipelines/tree/master/extra/frameworks\" target=\"_blank\">this section</a> for a Local <em>Metaflow</em> installation. This comes in handy for quick prototyping and testing.\n",
    "</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe237f61",
   "metadata": {},
   "source": [
    "<font size=\"6em\"><b>Table of Contents</b></font>\n",
    "\n",
    "- [setup](#setup)\n",
    "- [Metaflow run](#Metaflow-run)\n",
    "  - [flow parameters](#flow-parameters)\n",
    "  - [Run flow](#Run-flow)\n",
    "    - [Use the as-is sample pipeline](#Use-the-as-is-sample-pipeline)\n",
    "    - [Customize you retraining pipeline](#Customize-you-retraining-pipeline)\n",
    "  - [Tensorboard](#Tensorboard)\n",
    "- [Inspectors](#Inspectors)\n",
    "  - [local Metaflow SDK](#local-Metaflow-SDK)\n",
    "  - [local custom card explorer](#local-custom-card-explorer)\n",
    "  - [model version history](#model-version-history)\n",
    "- [Congratulations&nbsp;!](#Congratulationsnbsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4680109",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7cbc9c",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a05565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install retrain-pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json\n",
    "from textwrap import dedent\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "# print(find_dotenv())\n",
    "print(load_dotenv(os.path.join(os.getcwd(), \"..\", \"..\", \".env\")))\n",
    "hf_token = os.environ[\"HF_TOKEN\"]\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"PyTorch {torch.__version__}\")\n",
    "engine = \"gpu\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2c430",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b457cb",
   "metadata": {},
   "source": [
    "# Metaflow run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ef9cf",
   "metadata": {},
   "source": [
    "## flow parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8300f552",
   "metadata": {},
   "source": [
    "Choose which datasets shall be used as the pipeline <u>base function-calls</u> and <u>generic data-enrichment</u> datasets&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221133ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrain_pipelines.utils import as_env_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29beaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_env_var(\n",
    "    {\"repo_id\": \"Salesforce/xlam-function-calling-60k\",\n",
    "     \"commit_hash\": \"\",\n",
    "     \"config_name\": \"\",\n",
    "     \"attributes\": {\"query_attr\": \"query\", \"answers_attr\": \"answers\", \"tools_attr\": \"tools\"}},\n",
    "    env_var_name=\"hf_dataset_flow_param\"\n",
    ")\n",
    "print(f\"hf_dataset_flow_param : {os.environ['hf_dataset_flow_param']}\")\n",
    "\n",
    "as_env_var(\n",
    "    {\"repo_id\": \"lighteval/natural_questions_clean\",\n",
    "     \"commit_hash\": \"\",\n",
    "     \"config_name\": \"\",\n",
    "     \"query_attribute\": \"question\",\n",
    "     \"query_attribute_handler\": \"lambda x: x\"},\n",
    "    env_var_name=\"hf_enrich_dataset_flow_param\"\n",
    ")\n",
    "print(f\"hf_enrich_dataset_flow_param : {os.environ['hf_enrich_dataset_flow_param']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab4e60",
   "metadata": {},
   "source": [
    "Choose which model shall be used as the pipeline <u>base model</u>&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa87ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_env_var(\n",
    "    {\"repo_id\": \"unsloth/Qwen2.5-1.5B\",\n",
    "     \"commit_hash\": \"\"},\n",
    "    env_var_name=\"hf_base_model_flow_param\"\n",
    ")\n",
    "print(f\"hf_base_model_flow_param : {os.environ['hf_base_model_flow_param']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9523b6c3",
   "metadata": {},
   "source": [
    "Set the TrainingArgument values to respectively apply to the <u>CPT</u> and <u>SFT</u> tasks for your run&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe2576",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_env_var(\n",
    "    {\"warmup_ratio\": 0.1,\n",
    "     \"num_train_epochs\": 1},\n",
    "    env_var_name=\"cpt_training_args_flow_param\"\n",
    ")\n",
    "print(f\"cpt_training_args_flow_param : {os.environ['cpt_training_args_flow_param']}\")\n",
    "\n",
    "as_env_var(\n",
    "    {\"warmup_ratio\": 0.1,\n",
    "     \"num_train_epochs\": 1},\n",
    "    env_var_name=\"sft_training_args_flow_param\"\n",
    ")\n",
    "print(f\"sft_training_args_flow_param : {os.environ['sft_training_args_flow_param']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc1f971",
   "metadata": {},
   "source": [
    "Define the <code>repo_id</code> values for the <u>dataset-version</u> and <u>model-version</u> artifacts to be pushed on the <b>Hugging Face Hub</b> as they are generated when the pipeline executes.<br />\n",
    "Be sure to use an HF_TOKEN which grants <u>write permission</u> on them&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea58970",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['dataset_repo_id_flow_param'] = <your_target_dataset_repo_id>\n",
    "os.environ['model_repo_id_flow_param'] = <your_target_model_repo_id>\n",
    "print(f\"\\n{os.environ['dataset_repo_id_flow_param']}\\n{os.environ['model_repo_id_flow_param']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6df49",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873d984",
   "metadata": {
    "hidden": true
   },
   "source": [
    "During execution of this <b>retrain-pipeline</b> sample pipeline run, you can see training logs in real time since they are live-streamed in your local <a href=\"../../serving_artifacts/UnslothFuncCallFlow\" target=\"_blank\">serving_artifacts/</a> directory&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b802afa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mf_run_id = 1985\n",
    "log_dir = os.path.join(\n",
    "    os.path.dirname(os.path.dirname(os.getcwd())),\n",
    "    \"serving_artifacts\", \"UnslothFuncCallFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75987a",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.environ['TENSORBOARD_BINARY'] = \"<path_to_your_python_venv>/bin/tensorboard\"\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {logdir} --load_fast=false --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698c2da",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Go to your <em>TensorBoard</em> web console&nbsp;:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e63121",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a target=\"_blank\" href=\"http://localhost:6006/?darkMode=true#timeseries\">http://localhost:6006/?darkMode=true#timeseries</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd189005",
   "metadata": {},
   "source": [
    "## Run flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0448f",
   "metadata": {},
   "source": [
    "### Use the as-is sample pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c3de9",
   "metadata": {},
   "source": [
    "Load the cell-magic&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041bb531",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext retrain_pipelines.legacy_launcher_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336a747",
   "metadata": {},
   "source": [
    "Take a look at the help for the retraining pipeline&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f896779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%retrain_pipelines_legacy retraining_pipeline.py run --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757c5b8",
   "metadata": {},
   "source": [
    "You can launch a <b>retrain-pipelines</b> run&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cc44c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%retrain_pipelines_legacy retraining_pipeline.py run \\\n",
    "    --hf_dataset '{hf_dataset_flow_param}' \\\n",
    "    --hf_enrich_dataset '{hf_enrich_dataset_flow_param}' \\\n",
    "    --hf_base_model '{hf_base_model_flow_param}' \\\n",
    "    --dataset_repo_id '{dataset_repo_id_flow_param}' \\\n",
    "    --cpt_training_args '{cpt_training_args_flow_param}' \\\n",
    "    --sft_training_args '{sft_training_args_flow_param}' \\\n",
    "    --model_repo_id '{model_repo_id_flow_param}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a56850",
   "metadata": {},
   "source": [
    "You can also resume a prior run from the step of your choosing&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6b147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%retrain_pipelines_legacy retraining_pipeline.py resume model_version_blessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e96c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%retrain_pipelines_legacy retraining_pipeline.py resume infra_validator --origin-run-id 1708"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87e1bf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Customize you retraining pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af801d13",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Start by getting the default which you'd like to customize (any combinaison of the below 6 you'd like)&nbsp;:\n",
    "<ul>\n",
    "    <li><code>dataset_readme.py</code> module</li>\n",
    "    <li><code>dataset_readme_template.md</code> markdown template</li>\n",
    "    <li><code>model_readme.py</code> module</li>\n",
    "    <li><code>model_readme_template.md</code> markdown template</li>\n",
    "    <li><code>pipeline_card.py</code> module</li>\n",
    "    <li><code>template.html</code> html template</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2148439c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from retraining_pipeline import UnslothFuncCallFlow\n",
    "\n",
    "UnslothFuncCallFlow.copy_default_dataset_readme_module(\".\", exists_ok=True)\n",
    "UnslothFuncCallFlow.copy_default_dataset_readme_template(\".\", exists_ok=True)\n",
    "UnslothFuncCallFlow.copy_default_model_readme_module(\".\", exists_ok=True)\n",
    "UnslothFuncCallFlow.copy_default_model_readme_template(\".\", exists_ok=True)\n",
    "UnslothFuncCallFlow.copy_default_pipeline_card_module(\".\", exists_ok=True)\n",
    "UnslothFuncCallFlow.copy_default_pipeline_card_html_template(\".\", exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1876a01",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once you updated any of them, you can launch a <b>retrain-pipelines</b> run so it uses those&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc519c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%retrain_pipelines_legacy retraining_pipeline.py run \\\n",
    "    --hf_dataset '{hf_dataset_flow_param}' \\\n",
    "    --hf_enrich_dataset '{hf_enrich_dataset_flow_param}' \\\n",
    "    --hf_base_model '{hf_base_model_flow_param}' \\\n",
    "    --dataset_repo_id '{dataset_repo_id_flow_param}' \\\n",
    "    --cpt_training_args '{cpt_training_args_flow_param}' \\\n",
    "    --sft_training_args '{sft_training_args_flow_param}' \\\n",
    "    --model_repo_id '{model_repo_id_flow_param}' \\\n",
    "    --pipeline_card_artifacts_path \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d1941",
   "metadata": {},
   "source": [
    "# Inspectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e496c5a",
   "metadata": {},
   "source": [
    "The <b>retrain-pipelines Inspectors</b> are a set of convenience methods to observe past runs <em>after-the-fact</em>. They're here to ease the discovery of some important facts which, for the sake of consicion, were not included in the <code>pipeline-card</code> generated for that run.<br />\n",
    "If for any reason you'd like to dig deeper in a past run and investigate in details what happened, you can rely on the <b>retrain-pipelines Inspectors</b>&nbsp;!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b769e860",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c9639",
   "metadata": {},
   "source": [
    "We can programatically interact with the Metaflow service using the `metaflow` python package. To connect the package with our self-hosted metaflow service, we simply need to set a couple environment variables before importing it&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61becd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_flow_name = \"UnslothFuncCallFlow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34894384",
   "metadata": {},
   "source": [
    "## local Metaflow SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175c31b",
   "metadata": {},
   "source": [
    "You can use the metaflow python package to navigate artifacts gennerated by a past <b>retrain-pipelines</b> run just as you would for any metaflow flow. To interact with your local metaflow instance though, you shall use the <code>local_metaflow</code> package as follows&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrain_pipelines.frameworks import local_metaflow as metaflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec69f8c",
   "metadata": {},
   "source": [
    "And explore the content of any given set of flow artifacts, just specify the right <code>flow_id</code> and <code>task_id</code> for it below to for instance retrieved the metadata of the newly-retrained model itself&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaflow.Task(\"UnslothFuncCallFlow/1708/pipeline_card/43002\",\n",
    "              attempt=0)['model_commit_dict'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5fc12",
   "metadata": {},
   "source": [
    "Or you could look into the evaluation resultset for a given run, with inference versus ground truth, for detailled error analysis&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1040902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaflow.Task(\"UnslothFuncCallFlow/1708/pipeline_card/43002\",\n",
    "              attempt=0)['validation_results'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde271f0",
   "metadata": {},
   "source": [
    "Or you could go copy python commands straight from the dedicated <b>key artifacts</b> section from your <code>pipeline card</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8714caa",
   "metadata": {},
   "source": [
    "## local custom card explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrain_pipelines.inspectors import browse_local_pipeline_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204d5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(browse_local_pipeline_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5aacb4",
   "metadata": {},
   "source": [
    "You can open the <code>pipeline card</code> corresponding to the latest run by simply calling&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0334ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "browse_local_pipeline_card(mf_flow_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24aec3",
   "metadata": {},
   "source": [
    "## model version history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a6acc",
   "metadata": {},
   "source": [
    "Retrieve the history of your model versions from the <b>Hugging Face</b> Hub&nbsp;!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrain_pipelines.inspectors.hf import get_model_versions_history\n",
    "\n",
    "model_repo_id = \"retrain-pipelines/function_caller\"\n",
    "\n",
    "model_versions_history = get_model_versions_history(\n",
    "    repo_id=model_repo_id,\n",
    "    hf_token=os.getenv(\"HF_TOKEN\", None),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.DataFrame(model_versions_history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354c2d7",
   "metadata": {},
   "source": [
    "Display it as a prettyfied html table&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrain_pipelines.inspectors.hf import model_versions_history_html_table\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(model_versions_history_html_table(\n",
    "    model_versions_history\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ace0c",
   "metadata": {},
   "source": [
    "Display it as a chart showing performance progress across versions&nbsp;!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77537cfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from retrain_pipelines.inspectors.hf import plot_model_versions_history\n",
    "\n",
    "plot_model_versions_history(\n",
    "    model_versions_history=model_versions_history,\n",
    "    main_metric_name = \"jaccard\" # \"f1\" # \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e35b585",
   "metadata": {},
   "source": [
    "# Congratulations&nbsp;!\n",
    "\n",
    "<br />\n",
    "<div style='background-color: rgba(0, 255, 255, 0.04); border: 1px solid rgba(0, 255, 255, .2);'>\n",
    "<div style='text-align: justify; margin-left: 5px; margin-right: 5px;'>\n",
    "You're now championing the <code>UnslothFuncCallFlow</code> sample pipeline from the <b>retrain-pipelines</b> library&nbsp;!\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Metaflow Unsloth venv",
   "language": "python",
   "name": "metaflow_unsloth_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "301.875px",
    "left": "21.2188px",
    "top": "137.125px",
    "width": "230.766px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
